{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy ultralytics scipy matplotlib scikit-learn jupyter\n",
    "%pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b9a1ce",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from ultralytics import YOLO\n",
    "import math\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e4018",
   "metadata": {},
   "source": [
    "# segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloSegmenter:\n",
    "    def __init__(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Инициализация модели сегментации.\n",
    "        model_path – путь к файлу модели.\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)  # Загружаем модель через ultralytics\n",
    "\n",
    "    def segment_frame(self, frame: np.ndarray) -> list:\n",
    "        \"\"\"\n",
    "        Обрабатывает один кадр и возвращает список детекций.\n",
    "        Каждая детекция – словарь с ключами:\n",
    "            'bbox': [x1, y1, x2, y2],\n",
    "            'mask': np.ndarray бинарная маска (значения 0 или 1),\n",
    "            'class': int (0 – пузырь в фокусе, 1 – пузырь вне фокуса),\n",
    "            'confidence': float\n",
    "        \"\"\"\n",
    "        # Выполняем инференс для одного кадра\n",
    "        results = self.model(frame)\n",
    "        result = results[0]  # При обработке одного кадра возвращается список из одного результата\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        # Извлекаем bounding boxes, оценки и классы\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes.xyxy.cpu().numpy()  # shape: (n, 4)\n",
    "            scores = result.boxes.conf.cpu().numpy()   # shape: (n,)\n",
    "            classes = result.boxes.cls.cpu().numpy()   # shape: (n,)\n",
    "        else:\n",
    "            boxes, scores, classes = [], [], []\n",
    "\n",
    "        # Извлекаем маски (если модель обучена на segmentation)\n",
    "        if result.masks is not None:\n",
    "            # result.masks.data имеет размер (n, height, width) – значения от 0 до 1\n",
    "            masks = result.masks.data.cpu().numpy()\n",
    "        else:\n",
    "            masks = [None] * len(boxes)\n",
    "\n",
    "        for i, bbox in enumerate(boxes):\n",
    "            mask = masks[i] if i < len(masks) else None\n",
    "            detection = {\n",
    "                'bbox': bbox.tolist(),\n",
    "                'mask': (mask > 0.5).astype(np.uint8) if mask is not None else None,\n",
    "                'class': int(classes[i]),\n",
    "                'confidence': float(scores[i])\n",
    "            }\n",
    "            detections.append(detection)\n",
    "\n",
    "        return detections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d576cc",
   "metadata": {},
   "source": [
    "# tracker_bytetrack.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ee9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"\n",
    "    Вычисляет IoU (Intersection over Union) для двух bounding box.\n",
    "    Формат bbox: [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    x1 = max(bbox1[0], bbox2[0])\n",
    "    y1 = max(bbox1[1], bbox2[1])\n",
    "    x2 = min(bbox1[2], bbox2[2])\n",
    "    y2 = min(bbox1[3], bbox2[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area1 = max(0, bbox1[2] - bbox1[0]) * max(0, bbox1[3] - bbox1[1])\n",
    "    area2 = max(0, bbox2[2] - bbox2[0]) * max(0, bbox2[3] - bbox2[1])\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    if union_area <= 0:\n",
    "        return 0.0\n",
    "    return inter_area / union_area\n",
    "\n",
    "class KalmanBoxTracker:\n",
    "    \"\"\"\n",
    "    Отслеживает отдельный объект с использованием полноценного Калмана.\n",
    "    Состояние: [x, y, s, r, vx, vy, vs]\n",
    "      x, y – координаты центра,\n",
    "      s – площадь (масштаб),\n",
    "      r – соотношение сторон (предполагается относительно стабильным),\n",
    "      vx, vy, vs – скорости соответствующих параметров.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "\n",
    "    def __init__(self, bbox, frame_idx, timestamp, detection=None):\n",
    "        \"\"\"\n",
    "        Инициализация трека по начальному bbox.\n",
    "        bbox: [x1, y1, x2, y2]\n",
    "        \"\"\"\n",
    "        self.id = KalmanBoxTracker.count\n",
    "        KalmanBoxTracker.count += 1\n",
    "\n",
    "        # Преобразуем bbox в измерение: [x, y, s, r]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        x = x1 + w / 2.0\n",
    "        y = y1 + h / 2.0\n",
    "        s = w * h\n",
    "        r = w / (h + 1e-6)\n",
    "\n",
    "        # Инициализируем состояние: [x, y, s, r, vx, vy, vs]\n",
    "        self.state = np.array([x, y, s, r, 0, 0, 0], dtype=np.float32)\n",
    "        # Начальная ковариация. Допустим, относительно точны координаты, но неопределенность в площади и особенно в скорости больше.\n",
    "        self.P = np.diag([10, 10, 100, 10, 1000, 1000, 1000]).astype(np.float32)\n",
    "\n",
    "        # Шаг времени по умолчанию (если не задан динамически) — 1 единица (1 кадр)\n",
    "        dt = 1.0  \n",
    "        # Матрица перехода состояния F для модели постоянной скорости.\n",
    "        # В дальнейшем будем обновлять компоненты, зависящие от dt.\n",
    "        self.F = np.array([\n",
    "            [1, 0, 0, 0, dt,  0,   0],\n",
    "            [0, 1, 0, 0,  0, dt,   0],\n",
    "            [0, 0, 1, 0,  0,  0,  dt],\n",
    "            [0, 0, 0, 1,  0,  0,   0],\n",
    "            [0, 0, 0, 0,  1,  0,   0],\n",
    "            [0, 0, 0, 0,  0,  1,   0],\n",
    "            [0, 0, 0, 0,  0,  0,   1]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Матрица наблюдения H (мы измеряем только [x, y, s, r])\n",
    "        self.H = np.array([\n",
    "            [1, 0, 0, 0, 0, 0, 0],\n",
    "            [0, 1, 0, 0, 0, 0, 0],\n",
    "            [0, 0, 1, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 1, 0, 0, 0]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        # Матрица шума процесса Q — увеличим шум для скоростных компонент.\n",
    "        self.Q = np.diag([0.1, 0.1, 0.1, 0.001, 50, 50, 50]).astype(np.float32)\n",
    "        # Матрица шума измерения R — предполагаем, что измерения x, y относительно точны, площадь менее точна.\n",
    "        self.R = np.diag([0.5, 0.5, 10, 0.01]).astype(np.float32)\n",
    "\n",
    "        self.frame_idx = frame_idx\n",
    "        self.timestamp = timestamp\n",
    "        self.time_since_update = 0\n",
    "        self.history = [bbox]\n",
    "        self.detection = detection\n",
    "\n",
    "    def predict(self, dt=None):\n",
    "        \"\"\"\n",
    "        Выполняет предсказание нового состояния.\n",
    "        Если dt не задан, предполагаем dt = 1.0.\n",
    "        Если задан, обновляем матрицу перехода F.\n",
    "        \"\"\"\n",
    "        if dt is None:\n",
    "            dt = 1.0\n",
    "        # Обновляем dt в матрице перехода F\n",
    "        self.F[0, 4] = dt\n",
    "        self.F[1, 5] = dt\n",
    "        self.F[2, 6] = dt\n",
    "\n",
    "        self.state = np.dot(self.F, self.state)\n",
    "        self.P = np.dot(np.dot(self.F, self.P), self.F.T) + self.Q\n",
    "        self.time_since_update += 1\n",
    "        return self.get_state()\n",
    "\n",
    "    def update(self, bbox, frame_idx, timestamp, detection=None):\n",
    "        \"\"\"\n",
    "        Обновление состояния по новой детекции с использованием стандартного уравнения Калмана.\n",
    "        dt рассчитывается как разница между текущей временной меткой и предыдущей.\n",
    "        \"\"\"\n",
    "        # Рассчитываем dt по времени между текущей и предыдущей детекцией.\n",
    "        dt = timestamp - self.timestamp if self.timestamp is not None else 1.0\n",
    "        if dt <= 0:\n",
    "            dt = 1.0\n",
    "\n",
    "        # Обновляем матрицу перехода F с учетом dt\n",
    "        self.F[0, 4] = dt\n",
    "        self.F[1, 5] = dt\n",
    "        self.F[2, 6] = dt\n",
    "\n",
    "        # Преобразуем bbox в измерение: [x, y, s, r]\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        x = x1 + w / 2.0\n",
    "        y = y1 + h / 2.0\n",
    "        s = w * h\n",
    "        r = w / (h + 1e-6)\n",
    "        z = np.array([x, y, s, r], dtype=np.float32)\n",
    "\n",
    "        # Измеренная инновация: y = z - Hx\n",
    "        y_meas = z - np.dot(self.H, self.state)\n",
    "        # Инновационная ковариация: S = HPH^T + R\n",
    "        S = np.dot(np.dot(self.H, self.P), self.H.T) + self.R\n",
    "        # Оптимальное усиление Калмана: K = PH^T S^-1\n",
    "        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))\n",
    "        # Обновление состояния: x = x + Ky\n",
    "        self.state = self.state + np.dot(K, y_meas)\n",
    "        # Обновление ковариации: P = (I - KH)P\n",
    "        I = np.eye(self.F.shape[0], dtype=np.float32)\n",
    "        self.P = np.dot((I - np.dot(K, self.H)), self.P)\n",
    "\n",
    "        self.time_since_update = 0\n",
    "        self.frame_idx = frame_idx\n",
    "        self.timestamp = timestamp\n",
    "        self.history.append(bbox)\n",
    "        self.detection = detection\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Возвращает текущий bbox в формате [x1, y1, x2, y2] на основании текущего состояния.\n",
    "        Производится защита от отрицательных значений для s и r.\n",
    "        \"\"\"\n",
    "        x, y, s, r = self.state[0:4]\n",
    "        s = max(s, 1e-6)\n",
    "        r = max(r, 1e-6)\n",
    "        w = math.sqrt(s * r)\n",
    "        h = s / (w + 1e-6)\n",
    "        x1 = x - w / 2.0\n",
    "        y1 = y - h / 2.0\n",
    "        x2 = x + w / 2.0\n",
    "        y2 = y + h / 2.0\n",
    "        return [x1, y1, x2, y2]\n",
    "\n",
    "\n",
    "class ByteTracker:\n",
    "    def __init__(self, high_thresh=0.6, low_thresh=0.1, max_time_lost=10, iou_threshold=0.2, distance_threshold=50):\n",
    "        \"\"\"\n",
    "        Инициализация ByteTracker.\n",
    "          - high_thresh: порог для высокодоверенных детекций.\n",
    "          - low_thresh: порог для низкодоверенных детекций.\n",
    "          - max_time_lost: число кадров, в течение которых трек может оставаться без обновления.\n",
    "          - iou_threshold: порог IoU для сопоставления детекций с треками.\n",
    "          - distance_threshold: максимальное допустимое расстояние между центрами bbox для сопоставления.\n",
    "        \"\"\"\n",
    "        self.high_thresh = high_thresh\n",
    "        self.low_thresh = low_thresh\n",
    "        self.max_time_lost = max_time_lost\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.trackers = []\n",
    "        self.finished_tracks = []  # Для хранения завершённых треков\n",
    "\n",
    "    def update(self, detections, frame_idx, timestamp):\n",
    "        \"\"\"\n",
    "        Обновляет трекер по новым детекциям.\n",
    "        detections: список словарей с ключами 'bbox', 'confidence', 'mask', и т.д.\n",
    "        Возвращает словарь активных треков: {tracker_id: tracker_instance}.\n",
    "        \"\"\"\n",
    "        # Разбиваем детекции на высокодоверенные и низкодоверенные\n",
    "        high_detections = [det for det in detections if det['confidence'] >= self.high_thresh]\n",
    "        low_detections = [det for det in detections if self.low_thresh <= det['confidence'] < self.high_thresh]\n",
    "\n",
    "        high_boxes = np.array([det['bbox'] for det in high_detections]) if high_detections else np.empty((0, 4))\n",
    "        low_boxes = np.array([det['bbox'] for det in low_detections]) if low_detections else np.empty((0, 4))\n",
    "\n",
    "        # Предсказываем новое положение для всех треков\n",
    "        for tracker in self.trackers:\n",
    "            dt = timestamp - tracker.timestamp if tracker.timestamp is not None else 1.0\n",
    "            if dt <= 0:\n",
    "                dt = 1.0\n",
    "            tracker.predict(dt)\n",
    "        predicted_boxes = np.array([tracker.get_state() for tracker in self.trackers]) if self.trackers else np.empty((0, 4))\n",
    "\n",
    "        # 1. Сопоставляем высокодоверенные детекции с существующими треками\n",
    "        matches, unmatched_trackers, unmatched_detections = self.associate_detections_to_trackers(predicted_boxes, high_boxes)\n",
    "\n",
    "        # Обновляем треки, для которых найдено соответствие\n",
    "        for tracker_idx, detection_idx in matches:\n",
    "            self.trackers[tracker_idx].update(high_boxes[detection_idx], frame_idx, timestamp,\n",
    "                                              detection=high_detections[detection_idx])\n",
    "\n",
    "        # 2. Для оставшихся треков пытаемся сопоставить низкодоверенные детекции\n",
    "        if len(unmatched_trackers) > 0 and low_boxes.shape[0] > 0:\n",
    "            unmatched_predicted = predicted_boxes[unmatched_trackers]\n",
    "            matches_low, unmatched_trackers_final, unmatched_low = self.associate_detections_to_trackers(unmatched_predicted, low_boxes)\n",
    "            for local_tracker_idx, detection_idx in matches_low:\n",
    "                global_tracker_idx = unmatched_trackers[local_tracker_idx]\n",
    "                self.trackers[global_tracker_idx].update(low_boxes[detection_idx], frame_idx, timestamp,\n",
    "                                                          detection=low_detections[detection_idx])\n",
    "            unmatched_trackers = [unmatched_trackers[i] for i in unmatched_trackers_final]\n",
    "\n",
    "        # 3. Для треков, которым не нашли соответствия, увеличиваем счетчик пропусков\n",
    "        for idx in unmatched_trackers:\n",
    "            self.trackers[idx].time_since_update += 1\n",
    "\n",
    "        # 4. Создаем новые треки для высокодоверенных детекций, которым не нашли соответствия\n",
    "        for detection_idx in unmatched_detections:\n",
    "            det = high_detections[detection_idx]\n",
    "            new_tracker = KalmanBoxTracker(det['bbox'], frame_idx, timestamp, detection=det)\n",
    "            self.trackers.append(new_tracker)\n",
    "\n",
    "        # 5. Переносим треки, которые не обновлялись слишком долго, в finished_tracks\n",
    "        active_trackers = []\n",
    "        for tracker in self.trackers:\n",
    "            if tracker.time_since_update > self.max_time_lost:\n",
    "                self.finished_tracks.append(tracker)\n",
    "            else:\n",
    "                active_trackers.append(tracker)\n",
    "        self.trackers = active_trackers\n",
    "\n",
    "        # Возвращаем активные треки – считаем активными те, у которых time_since_update <= 1\n",
    "        active = {tracker.id: tracker for tracker in self.trackers if tracker.time_since_update <= 1}\n",
    "        return active\n",
    "\n",
    "    def associate_detections_to_trackers(self, trackers_boxes, detections_boxes):\n",
    "        \"\"\"\n",
    "        Сопоставляет детекции с треками с использованием матрицы IoU и комбинированного критерия.\n",
    "        Возвращает:\n",
    "            matches: список пар (tracker_idx, detection_idx)\n",
    "            unmatched_trackers: список индексов треков без сопоставления\n",
    "            unmatched_detections: список индексов детекций без сопоставления\n",
    "        \"\"\"\n",
    "        if trackers_boxes.shape[0] == 0 or detections_boxes.shape[0] == 0:\n",
    "            return [], list(range(trackers_boxes.shape[0])), list(range(detections_boxes.shape[0]))\n",
    "\n",
    "        # Вычисляем матрицу IoU\n",
    "        iou_matrix = np.zeros((trackers_boxes.shape[0], detections_boxes.shape[0]), dtype=np.float32)\n",
    "        for t, tb in enumerate(trackers_boxes):\n",
    "            for d, db in enumerate(detections_boxes):\n",
    "                iou_matrix[t, d] = iou(tb, db)\n",
    "\n",
    "        row_indices, col_indices = linear_sum_assignment(-iou_matrix)\n",
    "        matches = []\n",
    "        unmatched_trackers = []\n",
    "        unmatched_detections = []\n",
    "\n",
    "        # Для каждой пары (tracker, детекция) проверяем, если либо IoU достаточно высокое,\n",
    "        # либо центры bbox близки (евклидово расстояние меньше distance_threshold), то считаем их совпадающими.\n",
    "        for t, d in zip(row_indices, col_indices):\n",
    "            tb = trackers_boxes[t]\n",
    "            db = detections_boxes[d]\n",
    "            center_tracker = ((tb[0] + tb[2]) / 2.0, (tb[1] + tb[3]) / 2.0)\n",
    "            center_detection = ((db[0] + db[2]) / 2.0, (db[1] + db[3]) / 2.0)\n",
    "            dist = math.hypot(center_tracker[0] - center_detection[0],\n",
    "                              center_tracker[1] - center_detection[1])\n",
    "            if iou_matrix[t, d] >= self.iou_threshold or dist < self.distance_threshold:\n",
    "                matches.append((t, d))\n",
    "            else:\n",
    "                unmatched_trackers.append(t)\n",
    "                unmatched_detections.append(d)\n",
    "\n",
    "        # Добавляем те треки и детекции, которые не попали в алгоритм Хунгера\n",
    "        for t in range(trackers_boxes.shape[0]):\n",
    "            if t not in row_indices:\n",
    "                unmatched_trackers.append(t)\n",
    "        for d in range(detections_boxes.shape[0]):\n",
    "            if d not in col_indices:\n",
    "                unmatched_detections.append(d)\n",
    "        return matches, unmatched_trackers, unmatched_detections\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29479be9",
   "metadata": {},
   "source": [
    "# utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroid(bbox):\n",
    "    \"\"\"\n",
    "    Вычисляет центр bounding box в формате [x1, y1, x2, y2].\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    return ((x1 + x2) / 2, (y1 + y2) / 2)\n",
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    \"\"\"\n",
    "    Вычисляет евклидово расстояние между двумя точками.\n",
    "    \"\"\"\n",
    "    if p1 is None or p2 is None:\n",
    "        return float('inf')\n",
    "    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "def draw_mask(frame, mask, color, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Накладывает полупрозрачную маску на кадр.\n",
    "    mask: бинарная маска (0 или 1), размером, соответствующим кадру.\n",
    "    color: кортеж (B, G, R) – цвет для маски.\n",
    "    alpha: коэффициент прозрачности.\n",
    "    \"\"\"\n",
    "    # Убедимся, что маска имеет тип uint8 и размеры совпадают с изображением\n",
    "    mask = mask.astype(np.uint8)\n",
    "    if mask.shape[:2] != frame.shape[:2]:\n",
    "        mask = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    colored_mask = np.zeros_like(frame, dtype=np.uint8)\n",
    "    colored_mask[mask == 1] = color\n",
    "    frame = cv2.addWeighted(frame, 1, colored_mask, alpha, 0)\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87ecd1",
   "metadata": {},
   "source": [
    "# tracking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bubble:\n",
    "    def __init__(self, bubble_id: int, detection: dict, frame_idx: int, timestamp: float):\n",
    "        \"\"\"\n",
    "        Инициализация нового пузырька с уникальным ID и сохранением первой детекции.\n",
    "        \"\"\"\n",
    "        self.id = bubble_id\n",
    "        self.history = []  # История обновлений: список словарей с данными за каждый кадр\n",
    "        self.missed_frames = 0  # Счётчик пропущенных кадров (если объект не найден)\n",
    "        self.update(detection, frame_idx, timestamp)\n",
    "\n",
    "    def update(self, detection: dict, frame_idx: int, timestamp: float):\n",
    "        \"\"\"\n",
    "        Обновление информации о пузырьке новой детекцией. Рассчитывается скорость (пикселей/сек).\n",
    "        \"\"\"\n",
    "        bbox = detection.get('bbox', None)\n",
    "        mask = detection.get('mask', None)\n",
    "        detection_class = detection.get('class', None)\n",
    "        centroid = compute_centroid(bbox) if bbox is not None else None\n",
    "\n",
    "        # Вычисляем площадь: по маске (если есть) или по bbox\n",
    "        if mask is not None:\n",
    "            area = float(np.sum(mask > 0))\n",
    "        elif bbox is not None:\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            area = abs((x2 - x1) * (y2 - y1))\n",
    "        else:\n",
    "            area = 0\n",
    "\n",
    "        # Вычисляем скорость (если имеется предыдущая информация)\n",
    "        speed = 0.0\n",
    "        if self.history:\n",
    "            prev = self.history[-1]\n",
    "            prev_centroid = prev.get('centroid')\n",
    "            dt = timestamp - prev.get('timestamp', timestamp)\n",
    "            if centroid is not None and prev_centroid is not None and dt > 0:\n",
    "                speed = euclidean_distance(centroid, prev_centroid) / dt\n",
    "\n",
    "        self.history.append({\n",
    "            'frame_idx': frame_idx,\n",
    "            'timestamp': timestamp,\n",
    "            'centroid': centroid,\n",
    "            'bbox': bbox,\n",
    "            'area': area,\n",
    "            'class': detection_class,\n",
    "            'mask': mask,\n",
    "            'speed': speed\n",
    "        })\n",
    "        self.missed_frames = 0\n",
    "\n",
    "    def last_position(self):\n",
    "        \"\"\"\n",
    "        Возвращает последний известный центр и bbox.\n",
    "        \"\"\"\n",
    "        if self.history:\n",
    "            return self.history[-1]['centroid'], self.history[-1]['bbox']\n",
    "        return None, None\n",
    "\n",
    "class BubbleTracker:\n",
    "    def __init__(self, distance_threshold: float = 50.0, max_missed: int = 5):\n",
    "        \"\"\"\n",
    "        Инициализация трекера:\n",
    "          - distance_threshold: максимальное расстояние (в пикселях) для сопоставления детекции с существующим пузырьком;\n",
    "          - max_missed: число кадров, в течение которых объект может не детектироваться, прежде чем его удалить.\n",
    "        \"\"\"\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.max_missed = max_missed\n",
    "        self.tracked_bubbles = {}  # Словарь: bubble_id -> Bubble\n",
    "        self.next_id = 0\n",
    "\n",
    "    def update(self, detections: list, frame_idx: int, timestamp: float):\n",
    "        \"\"\"\n",
    "        Обновляет состояние трекера с детекциями текущего кадра.\n",
    "        Возвращает словарь текущих активных пузырьков.\n",
    "        \"\"\"\n",
    "        # Вычисляем центры для каждой детекции\n",
    "        detection_centroids = []\n",
    "        for det in detections:\n",
    "            bbox = det.get('bbox', None)\n",
    "            centroid = compute_centroid(bbox) if bbox is not None else None\n",
    "            detection_centroids.append(centroid)\n",
    "\n",
    "        # Собираем последние центры уже отслеживаемых пузырьков\n",
    "        tracked_ids = list(self.tracked_bubbles.keys())\n",
    "        tracked_centroids = []\n",
    "        for tid in tracked_ids:\n",
    "            cent, _ = self.tracked_bubbles[tid].last_position()\n",
    "            tracked_centroids.append(cent)\n",
    "\n",
    "        used_detection_indices = set()\n",
    "\n",
    "        # Жадное сопоставление: для каждого отслеживаемого объекта ищем ближайшую детекцию\n",
    "        for tid, track_centroid in zip(tracked_ids, tracked_centroids):\n",
    "            if track_centroid is None:\n",
    "                continue\n",
    "            min_dist = float('inf')\n",
    "            min_idx = -1\n",
    "            for i, det_centroid in enumerate(detection_centroids):\n",
    "                if i in used_detection_indices or det_centroid is None:\n",
    "                    continue\n",
    "                dist = euclidean_distance(track_centroid, det_centroid)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist\n",
    "                    min_idx = i\n",
    "            if min_idx != -1 and min_dist < self.distance_threshold:\n",
    "                # Обновляем существующий пузырёк\n",
    "                self.tracked_bubbles[tid].update(detections[min_idx], frame_idx, timestamp)\n",
    "                used_detection_indices.add(min_idx)\n",
    "            else:\n",
    "                # Если сопоставление не найдено – увеличиваем счётчик пропущенных кадров\n",
    "                self.tracked_bubbles[tid].missed_frames += 1\n",
    "\n",
    "        # Создаём новые объекты для оставшихся детекций\n",
    "        for i, det in enumerate(detections):\n",
    "            if i not in used_detection_indices:\n",
    "                bubble = Bubble(self.next_id, det, frame_idx, timestamp)\n",
    "                self.tracked_bubbles[self.next_id] = bubble\n",
    "                self.next_id += 1\n",
    "\n",
    "        # Удаляем объекты, которые пропустили слишком много кадров\n",
    "        remove_ids = [tid for tid, bubble in self.tracked_bubbles.items() if bubble.missed_frames > self.max_missed]\n",
    "        for tid in remove_ids:\n",
    "            del self.tracked_bubbles[tid]\n",
    "\n",
    "        return self.tracked_bubbles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d70eca",
   "metadata": {},
   "source": [
    "# video_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessor:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.segmenter = YoloSegmenter(model_path)\n",
    "        # Настраиваем трекер; параметры можно изменять\n",
    "        self.tracker = ByteTracker(high_thresh=0.6, low_thresh=0.1, max_time_lost=10, iou_threshold=0.2, distance_threshold=50)\n",
    "    def generate_histograms(self, hist_folder: str):\n",
    "        \"\"\"\n",
    "        Собирает все треки (активные + завершённые), выбирает топ-20 по длине жизни,\n",
    "        вычисляет для каждого скорость и площадь, строит гистограммы и сохраняет их как файлы.\n",
    "        Возвращает пути к файлам гистограмм (speed_hist_file, area_hist_file).\n",
    "        \"\"\"\n",
    "        # Объединяем завершённые и активные треки\n",
    "        all_tracks = self.tracker.finished_tracks + self.tracker.trackers\n",
    "        if not all_tracks:\n",
    "            return None, None\n",
    "\n",
    "        # Сортируем треки по числу кадров (длина истории)\n",
    "        sorted_tracks = sorted(all_tracks, key=lambda tr: len(tr.history), reverse=True)\n",
    "        top20 = sorted_tracks[:20]\n",
    "        speeds = []\n",
    "        areas = []\n",
    "        for tr in top20:\n",
    "            vx = tr.state[4]\n",
    "            vy = tr.state[5]\n",
    "            speed = math.sqrt(vx*vx + vy*vy)\n",
    "            speeds.append(speed)\n",
    "            areas.append(tr.state[2])\n",
    "\n",
    "        # Строим гистограмму скорости\n",
    "        plt.figure()\n",
    "        plt.hist(speeds, bins=10, color='blue', alpha=0.7)\n",
    "        plt.title(\"Гистограмма скорости (топ-20 долгоживущих)\")\n",
    "        plt.xlabel(\"Скорость (пикселей/кадр)\")\n",
    "        plt.ylabel(\"Частота\")\n",
    "        speed_hist_file = os.path.join(hist_folder, \"histogram_speed.png\")\n",
    "        plt.savefig(speed_hist_file)\n",
    "        plt.close()\n",
    "\n",
    "        # Строим гистограмму площади\n",
    "        plt.figure()\n",
    "        plt.hist(areas, bins=10, color='green', alpha=0.7)\n",
    "        plt.title(\"Гистограмма площади (топ-20 долгоживущих)\")\n",
    "        plt.xlabel(\"Площадь (пикселей^2)\")\n",
    "        plt.ylabel(\"Частота\")\n",
    "        area_hist_file = os.path.join(hist_folder, \"histogram_area.png\")\n",
    "        plt.savefig(area_hist_file)\n",
    "        plt.close()\n",
    "\n",
    "        return speed_hist_file, area_hist_file\n",
    "    \n",
    "\n",
    "    def process_video(self, input_video_path: str, output_video_path: str, csv_path: str, hist_folder: str):\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Ошибка: не удалось открыть видеофайл.\")\n",
    "            return None, None\n",
    "\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "        csv_file = open(csv_path, mode='w', newline='')\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['tracker_id', 'frame_idx', 'timestamp', 'centroid_x', 'centroid_y', 'area', 'class', 'speed'])\n",
    "\n",
    "        frame_idx = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            timestamp = frame_idx / fps\n",
    "\n",
    "            detections = self.segmenter.segment_frame(frame)\n",
    "            tracked_objects = self.tracker.update(detections, frame_idx, timestamp)\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            for tracker in tracked_objects.values():\n",
    "                bbox = tracker.get_state()  # [x1, y1, x2, y2]\n",
    "                cx = int((bbox[0] + bbox[2]) / 2)\n",
    "                cy = int((bbox[1] + bbox[3]) / 2)\n",
    "\n",
    "                detection = tracker.detection\n",
    "                if detection is None:\n",
    "                    continue\n",
    "                mask = detection.get('mask', None)\n",
    "                detection_class = detection.get('class', None)\n",
    "                color = (0, 255, 0) if detection_class == 0 else (0, 0, 255)\n",
    "\n",
    "                cv2.putText(annotated_frame,\n",
    "                            f\"ID: {tracker.id}\",\n",
    "                            (cx, cy - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            color,\n",
    "                            2)\n",
    "                if mask is not None:\n",
    "                    annotated_frame = draw_mask(annotated_frame, mask, color)\n",
    "\n",
    "                # Вычисляем скорость как sqrt(vx^2 + vy^2) из состояния трека\n",
    "                vx = tracker.state[4]\n",
    "                vy = tracker.state[5]\n",
    "                speed = math.sqrt(vx*vx + vy*vy)\n",
    "                # Площадь берем из state[2]\n",
    "                area = tracker.state[2]\n",
    "\n",
    "                csv_writer.writerow([\n",
    "                    tracker.id,\n",
    "                    frame_idx,\n",
    "                    timestamp,\n",
    "                    cx,\n",
    "                    cy,\n",
    "                    area,\n",
    "                    detection_class,\n",
    "                    speed\n",
    "                ])\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            frame_idx += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        csv_file.close()\n",
    "\n",
    "        # Генерируем гистограммы для топ-20 долгоживущих треков\n",
    "        speed_hist_file, area_hist_file = self.generate_histograms(hist_folder)\n",
    "        return speed_hist_file, area_hist_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4baa5dc",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d183c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"hf_model_repo/model.pt\"\n",
    "video_processor = VideoProcessor(MODEL_PATH)\n",
    "input_video_path = \"input_video/test3.mp4\"\n",
    "output_video_path = \"results3/output_video.mp4\"  \n",
    "csv_path = \"results3/tracking_data.csv\"            \n",
    "hist_folder = \"results3\"                         \n",
    "video_processor.process_video(input_video_path, output_video_path, csv_path, hist_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
